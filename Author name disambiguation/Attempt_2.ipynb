{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b21483a-fefa-4546-9734-510165dd7d31",
   "metadata": {},
   "source": [
    "## Attempt - 2\n",
    "Here I try to convert 'strings' dtype to one-hot vectors and try to make a CNN clasifier.\n",
    "Following -https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers This example\n",
    "\n",
    "Do read README.md/ipynb  file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013683a6-1ebc-40de-9f55-e7fea47424d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4685efec-ea1b-492b-b3ab-501cd5e2d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4bff5be-7dcb-4f95-9721-1041dd9f747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>jconf</th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>Explanation-based Failure Recovery</td>\n",
       "      <td>1987</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>AAAI</td>\n",
       "      <td>13048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>Time Representation Prolog Circuit Modelling</td>\n",
       "      <td>1991</td>\n",
       "      <td>Yossi Lichtenstein,Bob Welham,Ajay Gupta</td>\n",
       "      <td>ALPUK</td>\n",
       "      <td>39153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>Optimal Deployment Triggers Detecting Events</td>\n",
       "      <td>2004</td>\n",
       "      <td>Manish Bhide,Ajay Gupta,Mukul Joshi,Mukesh K. ...</td>\n",
       "      <td>DEXA</td>\n",
       "      <td>149270</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>Web Page Ranking Based Events</td>\n",
       "      <td>2004</td>\n",
       "      <td>Ajay Gupta,Manish Bhide,Mukesh K. Mohania</td>\n",
       "      <td>EC-Web</td>\n",
       "      <td>175996</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>AGATHA: An Integrated Expert System Test Diagn...</td>\n",
       "      <td>1991</td>\n",
       "      <td>Daryl Allred,Yossi Lichtenstein,Chris Preist,M...</td>\n",
       "      <td>IAAI</td>\n",
       "      <td>258611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author                                              title  year  \\\n",
       "0  Ajay Gupta                 Explanation-based Failure Recovery  1987   \n",
       "1  Ajay Gupta       Time Representation Prolog Circuit Modelling  1991   \n",
       "2  Ajay Gupta       Optimal Deployment Triggers Detecting Events  2004   \n",
       "3  Ajay Gupta                      Web Page Ranking Based Events  2004   \n",
       "4  Ajay Gupta  AGATHA: An Integrated Expert System Test Diagn...  1991   \n",
       "\n",
       "                                             authors   jconf     pid  label  \n",
       "0                                         Ajay Gupta    AAAI   13048      0  \n",
       "1           Yossi Lichtenstein,Bob Welham,Ajay Gupta   ALPUK   39153      0  \n",
       "2  Manish Bhide,Ajay Gupta,Mukul Joshi,Mukesh K. ...    DEXA  149270      2  \n",
       "3          Ajay Gupta,Manish Bhide,Mukesh K. Mohania  EC-Web  175996      2  \n",
       "4  Daryl Allred,Yossi Lichtenstein,Chris Preist,M...    IAAI  258611      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('Test_ag.csv')\n",
    "dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c701c3-37fe-4cad-bca3-8eb9f4686978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>jconf</th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Management Conflicting Obligations Self-Protec...</td>\n",
       "      <td>2005</td>\n",
       "      <td>Rema Ananthanarayanan,Mukesh K. Mohania,Ajay G...</td>\n",
       "      <td>ICAC</td>\n",
       "      <td>264268</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Policy Framework Autonomic Data Managemen</td>\n",
       "      <td>2004</td>\n",
       "      <td>Manish Bhide,Ajay Gupta,Mukul Joshi,Mukesh K. ...</td>\n",
       "      <td>ICAC</td>\n",
       "      <td>264291</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Using Lagrangean Relaxation Service Location P...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Zill-E-Huma Kamal,Ala I. Al-Fuqaha,Ajay Gupta</td>\n",
       "      <td>ICC</td>\n",
       "      <td>275987</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mobility-Pattern-Based Anomaly Detection Algor...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chaoli Cai,Ajay Gupta</td>\n",
       "      <td>ICC</td>\n",
       "      <td>276300</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Detection Masquerade Attacks Wireless Sensor N...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Vijay Bhuse,Ajay Gupta,Ala I. Al-Fuqaha</td>\n",
       "      <td>ICC</td>\n",
       "      <td>277587</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dynamic Access Control Framework Based On Events</td>\n",
       "      <td>2003</td>\n",
       "      <td>Manish Bhide,Sandeep Pandey,Ajay Gupta,Mukesh ...</td>\n",
       "      <td>ICDE</td>\n",
       "      <td>299548</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Towards Bringing Database Management Task Real...</td>\n",
       "      <td>2003</td>\n",
       "      <td>Ajay Gupta,Manish Bhide,Mukesh K. Mohania</td>\n",
       "      <td>ICDE</td>\n",
       "      <td>300057</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Enhanced Business Intelligence EROCS</td>\n",
       "      <td>2008</td>\n",
       "      <td>Manish Bhide,V. Chakravarthy,Ajay Gupta,Himans...</td>\n",
       "      <td>ICDE</td>\n",
       "      <td>302056</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hardware Diagnosis as Program Debugging</td>\n",
       "      <td>1987</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>388794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Efficient Design Boltzmann Machines</td>\n",
       "      <td>1990</td>\n",
       "      <td>Ajay Gupta,Wolfgang Maass</td>\n",
       "      <td>NIPS</td>\n",
       "      <td>515636</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Policy Driven Data Administration</td>\n",
       "      <td>2002</td>\n",
       "      <td>Vishal S. Batra,Jaijit Bhattacharya,Harish Cha...</td>\n",
       "      <td>POLICY</td>\n",
       "      <td>545651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Clustering short texts wikipedia</td>\n",
       "      <td>2007</td>\n",
       "      <td>Somnath Banerjee,Krishnan Ramanathan,Ajay Gupta</td>\n",
       "      <td>SIGIR</td>\n",
       "      <td>596099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LIPTUS: associating structured unstructured in...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Manish Bhide,Ajay Gupta,Rahul Gupta,Prasan Roy...</td>\n",
       "      <td>SIGMOD Conference</td>\n",
       "      <td>600181</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Retaining personal expression social search</td>\n",
       "      <td>2009</td>\n",
       "      <td>Praphul Chandra,Ajay Gupta</td>\n",
       "      <td>WWW</td>\n",
       "      <td>675629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Some issues privacy data management</td>\n",
       "      <td>2007</td>\n",
       "      <td>Mukesh K. Mohania,Rema Ananthanarayanan,Ajay G...</td>\n",
       "      <td>Data Knowl. Eng.</td>\n",
       "      <td>846439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mutual Exclusion a Hypercube</td>\n",
       "      <td>1993</td>\n",
       "      <td>Ajay Gupta,Steven C. Bruell,Sukumar Ghosh</td>\n",
       "      <td>J. Parallel Distrib. Comput.</td>\n",
       "      <td>988870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Multivariate Integration Hypercubic Mesh Networks</td>\n",
       "      <td>1998</td>\n",
       "      <td>Elise de Doncker,Ajay K. Gupta</td>\n",
       "      <td>Parallel Computing</td>\n",
       "      <td>1034401</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Power Consumption Analysis Maximum A Posterior...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Zill-E-Huma Kamal,Ajay Gupta,Ashfaq A. Khokhar...</td>\n",
       "      <td>IEEE Trans. Parallel Distrib. Syst.</td>\n",
       "      <td>1126381</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IT Infrastructure Emerging Markets: Arguing En...</td>\n",
       "      <td>2006</td>\n",
       "      <td>Ajay Gupta,Parthasarathy Ranganathan,Prashant ...</td>\n",
       "      <td>IEEE Pervasive Computing</td>\n",
       "      <td>1179332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Power Efficient Algorithms Computing Fast Four...</td>\n",
       "      <td>2006</td>\n",
       "      <td>Turkmen Canli,Ajay Gupta,Ashfaq Khokhar</td>\n",
       "      <td>AICCSA</td>\n",
       "      <td>1205032</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Enabling analysts managed services CRM analytics</td>\n",
       "      <td>2009</td>\n",
       "      <td>Indrajit Bhattacharya,Shantanu Godbole,Ajay Gu...</td>\n",
       "      <td>KDD</td>\n",
       "      <td>1212517</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Document Summarization Wikipedia</td>\n",
       "      <td>2009</td>\n",
       "      <td>Krishnan Ramanathan,Yogesh Sankarasubramaniam,...</td>\n",
       "      <td>Online Information Review</td>\n",
       "      <td>1265282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Performance Indicators a 802.11 WLAN Deployment.</td>\n",
       "      <td>2009</td>\n",
       "      <td>Ajay Gupta,Prabhash Dhyani</td>\n",
       "      <td>U</td>\n",
       "      <td>1316053</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Towards Automated Privacy Compliance Informati...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Rema Ananthanarayanan,Ajay Gupta,Mukesh Mohania</td>\n",
       "      <td>Advances in Web Semantics I: Ontologies, Web S...</td>\n",
       "      <td>1384744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Simulation Detection Self-Propagating Worms Vi...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>U</td>\n",
       "      <td>1393934</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A workstation's communication performance benc...</td>\n",
       "      <td>1996</td>\n",
       "      <td>Kurt Maly,Ajay Gupta,Satish Mynam</td>\n",
       "      <td>Selected proceedings of the IFIP TC6 9th inter...</td>\n",
       "      <td>1398544</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Synchronization distributed systems</td>\n",
       "      <td>1989</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>U</td>\n",
       "      <td>1490190</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Largeandmdash;scale parallel numerical integra...</td>\n",
       "      <td>1999</td>\n",
       "      <td>Elise de Doncker,Ajay Gupta,Rodger R. Zanny</td>\n",
       "      <td>Journal of Computational and Applied Mathematics</td>\n",
       "      <td>1549674</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A method efficient design Boltzmann machines c...</td>\n",
       "      <td>1990</td>\n",
       "      <td>Ajay Gupta,Wolfgang Maass</td>\n",
       "      <td>Proceedings of the 1990 conference on Advances...</td>\n",
       "      <td>1671104</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>On complexity computation learning neural netw...</td>\n",
       "      <td>1991</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>U</td>\n",
       "      <td>1678096</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Hack I.T.: security through penetration testing</td>\n",
       "      <td>2002</td>\n",
       "      <td>T. J. Klevinsky,Scott Laliberte,Ajay Gupta</td>\n",
       "      <td>U</td>\n",
       "      <td>1739014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  year  \\\n",
       "5   Management Conflicting Obligations Self-Protec...  2005   \n",
       "6           Policy Framework Autonomic Data Managemen  2004   \n",
       "7   Using Lagrangean Relaxation Service Location P...  2008   \n",
       "8   Mobility-Pattern-Based Anomaly Detection Algor...  2008   \n",
       "9   Detection Masquerade Attacks Wireless Sensor N...  2007   \n",
       "10   Dynamic Access Control Framework Based On Events  2003   \n",
       "11  Towards Bringing Database Management Task Real...  2003   \n",
       "12               Enhanced Business Intelligence EROCS  2008   \n",
       "13            Hardware Diagnosis as Program Debugging  1987   \n",
       "14                Efficient Design Boltzmann Machines  1990   \n",
       "15                  Policy Driven Data Administration  2002   \n",
       "16                   Clustering short texts wikipedia  2007   \n",
       "17  LIPTUS: associating structured unstructured in...  2007   \n",
       "18        Retaining personal expression social search  2009   \n",
       "19                Some issues privacy data management  2007   \n",
       "20                       Mutual Exclusion a Hypercube  1993   \n",
       "21  Multivariate Integration Hypercubic Mesh Networks  1998   \n",
       "22  Power Consumption Analysis Maximum A Posterior...  2008   \n",
       "23  IT Infrastructure Emerging Markets: Arguing En...  2006   \n",
       "24  Power Efficient Algorithms Computing Fast Four...  2006   \n",
       "25   Enabling analysts managed services CRM analytics  2009   \n",
       "26                   Document Summarization Wikipedia  2009   \n",
       "27   Performance Indicators a 802.11 WLAN Deployment.  2009   \n",
       "28  Towards Automated Privacy Compliance Informati...  2008   \n",
       "29  Simulation Detection Self-Propagating Worms Vi...  2008   \n",
       "30  A workstation's communication performance benc...  1996   \n",
       "31                Synchronization distributed systems  1989   \n",
       "32  Largeandmdash;scale parallel numerical integra...  1999   \n",
       "33  A method efficient design Boltzmann machines c...  1990   \n",
       "34  On complexity computation learning neural netw...  1991   \n",
       "35    Hack I.T.: security through penetration testing  2002   \n",
       "\n",
       "                                              authors  \\\n",
       "5   Rema Ananthanarayanan,Mukesh K. Mohania,Ajay G...   \n",
       "6   Manish Bhide,Ajay Gupta,Mukul Joshi,Mukesh K. ...   \n",
       "7       Zill-E-Huma Kamal,Ala I. Al-Fuqaha,Ajay Gupta   \n",
       "8                               Chaoli Cai,Ajay Gupta   \n",
       "9             Vijay Bhuse,Ajay Gupta,Ala I. Al-Fuqaha   \n",
       "10  Manish Bhide,Sandeep Pandey,Ajay Gupta,Mukesh ...   \n",
       "11          Ajay Gupta,Manish Bhide,Mukesh K. Mohania   \n",
       "12  Manish Bhide,V. Chakravarthy,Ajay Gupta,Himans...   \n",
       "13                                         Ajay Gupta   \n",
       "14                          Ajay Gupta,Wolfgang Maass   \n",
       "15  Vishal S. Batra,Jaijit Bhattacharya,Harish Cha...   \n",
       "16    Somnath Banerjee,Krishnan Ramanathan,Ajay Gupta   \n",
       "17  Manish Bhide,Ajay Gupta,Rahul Gupta,Prasan Roy...   \n",
       "18                         Praphul Chandra,Ajay Gupta   \n",
       "19  Mukesh K. Mohania,Rema Ananthanarayanan,Ajay G...   \n",
       "20          Ajay Gupta,Steven C. Bruell,Sukumar Ghosh   \n",
       "21                     Elise de Doncker,Ajay K. Gupta   \n",
       "22  Zill-E-Huma Kamal,Ajay Gupta,Ashfaq A. Khokhar...   \n",
       "23  Ajay Gupta,Parthasarathy Ranganathan,Prashant ...   \n",
       "24            Turkmen Canli,Ajay Gupta,Ashfaq Khokhar   \n",
       "25  Indrajit Bhattacharya,Shantanu Godbole,Ajay Gu...   \n",
       "26  Krishnan Ramanathan,Yogesh Sankarasubramaniam,...   \n",
       "27                         Ajay Gupta,Prabhash Dhyani   \n",
       "28    Rema Ananthanarayanan,Ajay Gupta,Mukesh Mohania   \n",
       "29                                         Ajay Gupta   \n",
       "30                  Kurt Maly,Ajay Gupta,Satish Mynam   \n",
       "31                                         Ajay Gupta   \n",
       "32        Elise de Doncker,Ajay Gupta,Rodger R. Zanny   \n",
       "33                          Ajay Gupta,Wolfgang Maass   \n",
       "34                                         Ajay Gupta   \n",
       "35         T. J. Klevinsky,Scott Laliberte,Ajay Gupta   \n",
       "\n",
       "                                                jconf      pid  label  \n",
       "5                                                ICAC   264268      2  \n",
       "6                                                ICAC   264291      2  \n",
       "7                                                 ICC   275987      4  \n",
       "8                                                 ICC   276300      4  \n",
       "9                                                 ICC   277587      4  \n",
       "10                                               ICDE   299548      2  \n",
       "11                                               ICDE   300057      2  \n",
       "12                                               ICDE   302056      2  \n",
       "13                                              IJCAI   388794      0  \n",
       "14                                               NIPS   515636      7  \n",
       "15                                             POLICY   545651      2  \n",
       "16                                              SIGIR   596099      0  \n",
       "17                                  SIGMOD Conference   600181      2  \n",
       "18                                                WWW   675629      0  \n",
       "19                                   Data Knowl. Eng.   846439      2  \n",
       "20                       J. Parallel Distrib. Comput.   988870      3  \n",
       "21                                 Parallel Computing  1034401      4  \n",
       "22                IEEE Trans. Parallel Distrib. Syst.  1126381      4  \n",
       "23                           IEEE Pervasive Computing  1179332      0  \n",
       "24                                             AICCSA  1205032      4  \n",
       "25                                                KDD  1212517      2  \n",
       "26                          Online Information Review  1265282      0  \n",
       "27                                                  U  1316053      5  \n",
       "28  Advances in Web Semantics I: Ontologies, Web S...  1384744      2  \n",
       "29                                                  U  1393934      6  \n",
       "30  Selected proceedings of the IFIP TC6 9th inter...  1398544      8  \n",
       "31                                                  U  1490190      3  \n",
       "32   Journal of Computational and Applied Mathematics  1549674      4  \n",
       "33  Proceedings of the 1990 conference on Advances...  1671104      7  \n",
       "34                                                  U  1678096      7  \n",
       "35                                                  U  1739014      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.pop('author')\n",
    "dataframe = dataframe.where(dataframe.notnull(), 'U')\n",
    "dataframe.isna()\n",
    "dataframe.tail(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18c3f802-a975-4174-98df-fdd0c596cc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Multivariate Integration Hypercubic Mesh Networks',\n",
       "  'year': 1998,\n",
       "  'authors': 'Elise de Doncker,Ajay K. Gupta',\n",
       "  'jconf': 'Parallel Computing',\n",
       "  'pid': 1034401,\n",
       "  'label': 4},\n",
       " {'title': 'Simulation Detection Self-Propagating Worms Viruses',\n",
       "  'year': 2008,\n",
       "  'authors': 'Ajay Gupta',\n",
       "  'jconf': 'U',\n",
       "  'pid': 1393934,\n",
       "  'label': 6},\n",
       " {'title': 'IT Infrastructure Emerging Markets: Arguing End-to-End Perspective',\n",
       "  'year': 2006,\n",
       "  'authors': 'Ajay Gupta,Parthasarathy Ranganathan,Prashant Sarin,Mehul A. Shah',\n",
       "  'jconf': 'IEEE Pervasive Computing',\n",
       "  'pid': 1179332,\n",
       "  'label': 0},\n",
       " {'title': 'Enabling analysts managed services CRM analytics',\n",
       "  'year': 2009,\n",
       "  'authors': 'Indrajit Bhattacharya,Shantanu Godbole,Ajay Gupta,Ashish Verma,Jeff Achtermann,Kevin English',\n",
       "  'jconf': 'KDD',\n",
       "  'pid': 1212517,\n",
       "  'label': 2},\n",
       " {'title': 'Management Conflicting Obligations Self-Protecting Policy-Based Systems',\n",
       "  'year': 2005,\n",
       "  'authors': 'Rema Ananthanarayanan,Mukesh K. Mohania,Ajay Gupta',\n",
       "  'jconf': 'ICAC',\n",
       "  'pid': 264268,\n",
       "  'label': 2},\n",
       " {'title': 'Time Representation Prolog Circuit Modelling',\n",
       "  'year': 1991,\n",
       "  'authors': 'Yossi Lichtenstein,Bob Welham,Ajay Gupta',\n",
       "  'jconf': 'ALPUK',\n",
       "  'pid': 39153,\n",
       "  'label': 0},\n",
       " {'title': 'Efficient Design Boltzmann Machines',\n",
       "  'year': 1990,\n",
       "  'authors': 'Ajay Gupta,Wolfgang Maass',\n",
       "  'jconf': 'NIPS',\n",
       "  'pid': 515636,\n",
       "  'label': 7},\n",
       " {'title': 'Towards Bringing Database Management Task Realm IT non-Experts',\n",
       "  'year': 2003,\n",
       "  'authors': 'Ajay Gupta,Manish Bhide,Mukesh K. Mohania',\n",
       "  'jconf': 'ICDE',\n",
       "  'pid': 300057,\n",
       "  'label': 2}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "# print(len(train), 'train examples')\n",
    "# print(len(val), 'validation examples')\n",
    "test.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ce91c2-5806-4bd3-af85-e37d4d747281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('label')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c3a6d0-ee1a-4d55-9e5f-b581458af416",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95627ab9-5932-48f5-ba4c-3677177f0bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['title', 'year', 'authors', 'jconf', 'pid']\n",
      "A batch of ages: tf.Tensor(\n",
      "[b'Retaining personal expression social search'\n",
      " b'Power Efficient Algorithms Computing Fast Fourier Transform over Wireless Sensor Networks'\n",
      " b'Efficient Design Boltzmann Machines'\n",
      " b'Enabling analysts managed services CRM analytics'\n",
      " b'On complexity computation learning neural networks'], shape=(5,), dtype=string)\n",
      "A batch of targets: tf.Tensor([0 4 7 2 7], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['title'])\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22883517-8ec9-4f72-8e11-b8b076735865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = preprocessing.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a27965b4-42fd-44d2-a127-24c855f49d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[ 1.0981017 ],\n",
       "       [ 0.68863785],\n",
       "       [-1.4951699 ],\n",
       "       [ 1.0981017 ],\n",
       "       [-1.3586818 ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_count_col = train_features['year']\n",
    "layer = get_normalization_layer('year', train_ds)\n",
    "layer(photo_count_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2baf3f4-c8c8-4f63-a431-926a998ba093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a StringLookup layer which will turn strings into integer indices\n",
    "  if dtype == 'string':\n",
    "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = preprocessing.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b868053-b026-4568-a153-5505a63e14a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 24), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['title']\n",
    "layer = get_category_encoding_layer('title', train_ds, 'string')\n",
    "layer(type_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ae9943-e5a2-465d-803d-2fdf128c27c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 21), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['authors']\n",
    "author_encoding_layer = get_category_encoding_layer('authors', train_ds,\n",
    "                                                      'string')\n",
    "author_encoding_layer(type_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c5df1a8-0439-482f-b5db-13d8ed87f432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 21), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['jconf']\n",
    "jconf_encoding_layer = get_category_encoding_layer('jconf', train_ds,\n",
    "                                                      'string')\n",
    "jconf_encoding_layer(type_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8995bd84-7c8f-404e-ac86-fb95dc34c0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['pid']\n",
    "pid_encoding_layer = get_category_encoding_layer('pid', train_ds,\n",
    "                                                      'int64', 5)\n",
    "pid_encoding_layer(type_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b3b991e-34f8-4e2e-b2f6-fd23e831da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c8e9954-3bc8-4280-9f8f-10ffff89d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "744e3337-ff3e-43bb-8452-e0abb2146f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric features.\n",
    "for header in ['pid']:\n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21a1c1d3-8a8f-475e-ad86-f48cb3497c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers.\n",
    "age_col = tf.keras.Input(shape=(1,), name='year', dtype='int64')\n",
    "encoding_layer = get_category_encoding_layer('year', train_ds, dtype='int64',\n",
    "                                             max_tokens=5)\n",
    "encoded_age_col = encoding_layer(age_col)\n",
    "all_inputs.append(age_col)\n",
    "encoded_features.append(encoded_age_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa5c27bd-2515-42a0-98c3-19919c67ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as string.\n",
    "categorical_cols = ['title', 'authors', 'jconf']\n",
    "for header in categorical_cols:\n",
    "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string',\n",
    "                                               max_tokens=5)\n",
    "  encoded_categorical_col = encoding_layer(categorical_col)\n",
    "  all_inputs.append(categorical_col)\n",
    "  encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab5d5184-bee3-484a-aa3c-2e6e8eed524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(50, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(all_inputs, output)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ea67359-291d-42d3-9f25-f885489e7412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# rankdir='LR' is used to make the graph horizontal.\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e886de7e-4e91-450f-b17a-0c48fa50ccfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6306 - accuracy: 0.1818 - val_loss: 1.0419 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5882 - accuracy: 0.1818 - val_loss: 0.9881 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2475 - accuracy: 0.1364 - val_loss: 0.9350 - val_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4000 - accuracy: 0.1818 - val_loss: 0.8817 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 41ms/step - loss: -0.0856 - accuracy: 0.1818 - val_loss: 0.8284 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6381 - accuracy: 0.1364 - val_loss: 0.7750 - val_accuracy: 0.3333\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4321 - accuracy: 0.1364 - val_loss: 0.7219 - val_accuracy: 0.3333\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5637 - accuracy: 0.1818 - val_loss: 0.6692 - val_accuracy: 0.3333\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4858 - accuracy: 0.1364 - val_loss: 0.6164 - val_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 42ms/step - loss: -0.2121 - accuracy: 0.1364 - val_loss: 0.5633 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2021a770a30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d29b1483-9332-4870-abb4-47f95be52876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4193 - accuracy: 0.2500\n",
      "Accuracy 0.25\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3900d8d0-f9cc-4328-b334-961d9b11c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Multivariate Integration Hypercubic Mesh Networks'], dtype=object)>, 'year': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1998])>, 'authors': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Elise de Doncker,Ajay K. Gupta'], dtype=object)>, 'jconf': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Parallel Computing'], dtype=object)>, 'pid': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1034401])>}\n",
      "[[0.13424955]]\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    'title': 'Multivariate Integration Hypercubic Mesh Networks',\n",
    "  'year': 1998,\n",
    "  'authors': 'Elise de Doncker,Ajay K. Gupta',\n",
    "  'jconf': 'Parallel Computing',\n",
    "  'pid': 1034401,\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "print(input_dict)\n",
    "predictions = model.predict(input_dict)\n",
    "# prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f229e-3869-4a15-aa99-38709c6f4467",
   "metadata": {},
   "source": [
    "## This is an early attempt to use a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d75fde2c-5b33-4e35-b05b-8a41870f9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a74b5a0-583d-4320-8215-3055e7465197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\KHADGA~1\\AppData\\Local\\Temp\\tmp55sajoec\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\KHADGA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp55sajoec', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=all_features,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[50, 50],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=len(LABELS)\n",
    "#     ,activation_fn='relu',batch_norm=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c840678-71a9-443f-a385-1da909b50616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.train(train_ds)\n",
    "# model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dae5374e-efbd-4440-9e72-9c7d8b68af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def input_fn(features, labels, training=True, batch_size=256):\n",
    "#     # Convert the inputs to a Dataset.\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "#     # Shuffle and repeat if you are in training mode.\n",
    "#     if training:\n",
    "#         dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "#     return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b26e6b1e-ab22-45ba-9f49-0b3d198c4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.train(input_fn=lambda: input_fn(train, labels, training=True),\n",
    "#     steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72108d1a-22ed-4f3f-a25c-86d6cd1d867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, training=True, batch_size=256):\n",
    "    if training :\n",
    "        dataset = df_to_dataset(train, batch_size=batch_size)\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c629e0c9-cb17-4875-a1bf-41bd081bd187",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to capture an EagerTensor without building a function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KHADGA~1\\AppData\\Local\\Temp/ipykernel_14616/4108280045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m classifier.train(input_fn=lambda: input_fn(train_ds, training=True),\n\u001b[0m\u001b[0;32m      2\u001b[0m     steps=5000)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m       features, labels, input_hooks = (\n\u001b[1;32m-> 1201\u001b[1;33m           self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n\u001b[0m\u001b[0;32m   1202\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1035\u001b[0m     \u001b[1;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     return estimator_util.parse_input_fn_result(\n\u001b[1;32m-> 1037\u001b[1;33m         self._call_input_fn(input_fn, mode))\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extract_batch_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[0;32m   1128\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_context'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KHADGA~1\\AppData\\Local\\Temp/ipykernel_14616/4108280045.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m classifier.train(input_fn=lambda: input_fn(train_ds, training=True),\n\u001b[0m\u001b[0;32m      2\u001b[0m     steps=5000)\n",
      "\u001b[1;32mC:\\Users\\KHADGA~1\\AppData\\Local\\Temp/ipykernel_14616/2482479145.py\u001b[0m in \u001b[0;36minput_fn\u001b[1;34m(dataset, training, batch_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mshuffle\u001b[1;34m(self, buffer_size, seed, reshuffle_each_iteration)\u001b[0m\n\u001b[0;32m   1428\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m     \"\"\"\n\u001b[1;32m-> 1430\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mShuffleDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreshuffle_each_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, buffer_size, seed, reshuffle_each_iteration)\u001b[0m\n\u001b[0;32m   4029\u001b[0m           **self._flat_structure)\n\u001b[0;32m   4030\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4031\u001b[1;33m       variant_tensor = gen_dataset_ops.shuffle_dataset(\n\u001b[0m\u001b[0;32m   4032\u001b[0m           \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4033\u001b[0m           \u001b[0mbuffer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mshuffle_dataset\u001b[1;34m(input_dataset, buffer_size, seed, seed2, output_types, output_shapes, reshuffle_each_iteration, name)\u001b[0m\n\u001b[0;32m   6464\u001b[0m     \u001b[0mreshuffle_each_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6465\u001b[0m   \u001b[0mreshuffle_each_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshuffle_each_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"reshuffle_each_iteration\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6466\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   6467\u001b[0m         \u001b[1;34m\"ShuffleDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6468\u001b[0m                           \u001b[0mbuffer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    515\u001b[0m                   preferred_dtype=default_dtype)\n\u001b[0;32m    516\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             values = ops.convert_to_tensor(\n\u001b[0m\u001b[0;32m    518\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1523\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1524\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1525\u001b[1;33m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[0m\u001b[0;32m   1526\u001b[0m                            \"building a function.\")\n\u001b[0;32m   1527\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to capture an EagerTensor without building a function."
     ]
    }
   ],
   "source": [
    "classifier.train(input_fn=lambda: input_fn(train_ds, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152d525-c7d4-445f-b850-68c308c54c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
