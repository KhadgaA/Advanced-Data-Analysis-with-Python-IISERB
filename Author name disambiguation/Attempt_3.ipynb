{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563c4e23-e139-4f3a-b7b7-0cb899b99726",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Attempt - 3\n",
    "   - This is an tf attempt to classify the author 'Ajay Gupta'\n",
    "This attempt tries to solve the problem of having 'string' types into a model, by converting the 'string' type values into one-hot vectors.\n",
    "## Problem faced:\n",
    "   - Not knowing how to correctly implement a clustering model.\n",
    "> Error : \n",
    ">>Received a feature column from TensorFlow v1, but this is a TensorFlow v2 Estimator. Please either use v2 feature columns (accessible via tf.feature_column.* in TF 2.x) with     this Estimator, or switch to a v1 Estimator for use with v1 feature columns (accessible via tf.compat.v1.estimator.* and tf.compat.v1.feature_column.*, respectively.\n",
    "    \n",
    "> The model used - A DNNClassifier\n",
    "\n",
    "Do read README.md/ipynb  file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a696848-d980-4d76-ba3c-008fbbdf034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632fee01-5f30-43c4-885d-6ea0479b8a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>jconf</th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>Explanation-based Failure Recovery</td>\n",
       "      <td>1987</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>AAAI</td>\n",
       "      <td>13048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>Time Representation Prolog Circuit Modelling</td>\n",
       "      <td>1991</td>\n",
       "      <td>Yossi Lichtenstein,Bob Welham,Ajay Gupta</td>\n",
       "      <td>ALPUK</td>\n",
       "      <td>39153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>Optimal Deployment Triggers Detecting Events</td>\n",
       "      <td>2004</td>\n",
       "      <td>Manish Bhide,Ajay Gupta,Mukul Joshi,Mukesh K. ...</td>\n",
       "      <td>DEXA</td>\n",
       "      <td>149270</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>Web Page Ranking Based Events</td>\n",
       "      <td>2004</td>\n",
       "      <td>Ajay Gupta,Manish Bhide,Mukesh K. Mohania</td>\n",
       "      <td>EC-Web</td>\n",
       "      <td>175996</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>AGATHA: An Integrated Expert System Test Diagn...</td>\n",
       "      <td>1991</td>\n",
       "      <td>Daryl Allred,Yossi Lichtenstein,Chris Preist,M...</td>\n",
       "      <td>IAAI</td>\n",
       "      <td>258611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author                                              title  year  \\\n",
       "0  Ajay Gupta                 Explanation-based Failure Recovery  1987   \n",
       "1  Ajay Gupta       Time Representation Prolog Circuit Modelling  1991   \n",
       "2  Ajay Gupta       Optimal Deployment Triggers Detecting Events  2004   \n",
       "3  Ajay Gupta                      Web Page Ranking Based Events  2004   \n",
       "4  Ajay Gupta  AGATHA: An Integrated Expert System Test Diagn...  1991   \n",
       "\n",
       "                                             authors   jconf     pid  label  \n",
       "0                                         Ajay Gupta    AAAI   13048      0  \n",
       "1           Yossi Lichtenstein,Bob Welham,Ajay Gupta   ALPUK   39153      0  \n",
       "2  Manish Bhide,Ajay Gupta,Mukul Joshi,Mukesh K. ...    DEXA  149270      2  \n",
       "3          Ajay Gupta,Manish Bhide,Mukesh K. Mohania  EC-Web  175996      2  \n",
       "4  Daryl Allred,Yossi Lichtenstein,Chris Preist,M...    IAAI  258611      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('Test_ag.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f1af6b-5ca3-494c-b9d0-ae21d35797eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>jconf</th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Management Conflicting Obligations Self-Protec...</td>\n",
       "      <td>2005</td>\n",
       "      <td>Rema Ananthanarayanan,Mukesh K. Mohania,Ajay G...</td>\n",
       "      <td>ICAC</td>\n",
       "      <td>264268</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Policy Framework Autonomic Data Managemen</td>\n",
       "      <td>2004</td>\n",
       "      <td>Manish Bhide,Ajay Gupta,Mukul Joshi,Mukesh K. ...</td>\n",
       "      <td>ICAC</td>\n",
       "      <td>264291</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Using Lagrangean Relaxation Service Location P...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Zill-E-Huma Kamal,Ala I. Al-Fuqaha,Ajay Gupta</td>\n",
       "      <td>ICC</td>\n",
       "      <td>275987</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mobility-Pattern-Based Anomaly Detection Algor...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chaoli Cai,Ajay Gupta</td>\n",
       "      <td>ICC</td>\n",
       "      <td>276300</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Detection Masquerade Attacks Wireless Sensor N...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Vijay Bhuse,Ajay Gupta,Ala I. Al-Fuqaha</td>\n",
       "      <td>ICC</td>\n",
       "      <td>277587</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dynamic Access Control Framework Based On Events</td>\n",
       "      <td>2003</td>\n",
       "      <td>Manish Bhide,Sandeep Pandey,Ajay Gupta,Mukesh ...</td>\n",
       "      <td>ICDE</td>\n",
       "      <td>299548</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Towards Bringing Database Management Task Real...</td>\n",
       "      <td>2003</td>\n",
       "      <td>Ajay Gupta,Manish Bhide,Mukesh K. Mohania</td>\n",
       "      <td>ICDE</td>\n",
       "      <td>300057</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Enhanced Business Intelligence EROCS</td>\n",
       "      <td>2008</td>\n",
       "      <td>Manish Bhide,V. Chakravarthy,Ajay Gupta,Himans...</td>\n",
       "      <td>ICDE</td>\n",
       "      <td>302056</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hardware Diagnosis as Program Debugging</td>\n",
       "      <td>1987</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>388794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Efficient Design Boltzmann Machines</td>\n",
       "      <td>1990</td>\n",
       "      <td>Ajay Gupta,Wolfgang Maass</td>\n",
       "      <td>NIPS</td>\n",
       "      <td>515636</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Policy Driven Data Administration</td>\n",
       "      <td>2002</td>\n",
       "      <td>Vishal S. Batra,Jaijit Bhattacharya,Harish Cha...</td>\n",
       "      <td>POLICY</td>\n",
       "      <td>545651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Clustering short texts wikipedia</td>\n",
       "      <td>2007</td>\n",
       "      <td>Somnath Banerjee,Krishnan Ramanathan,Ajay Gupta</td>\n",
       "      <td>SIGIR</td>\n",
       "      <td>596099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LIPTUS: associating structured unstructured in...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Manish Bhide,Ajay Gupta,Rahul Gupta,Prasan Roy...</td>\n",
       "      <td>SIGMOD Conference</td>\n",
       "      <td>600181</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Retaining personal expression social search</td>\n",
       "      <td>2009</td>\n",
       "      <td>Praphul Chandra,Ajay Gupta</td>\n",
       "      <td>WWW</td>\n",
       "      <td>675629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Some issues privacy data management</td>\n",
       "      <td>2007</td>\n",
       "      <td>Mukesh K. Mohania,Rema Ananthanarayanan,Ajay G...</td>\n",
       "      <td>Data Knowl. Eng.</td>\n",
       "      <td>846439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mutual Exclusion a Hypercube</td>\n",
       "      <td>1993</td>\n",
       "      <td>Ajay Gupta,Steven C. Bruell,Sukumar Ghosh</td>\n",
       "      <td>J. Parallel Distrib. Comput.</td>\n",
       "      <td>988870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Multivariate Integration Hypercubic Mesh Networks</td>\n",
       "      <td>1998</td>\n",
       "      <td>Elise de Doncker,Ajay K. Gupta</td>\n",
       "      <td>Parallel Computing</td>\n",
       "      <td>1034401</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Power Consumption Analysis Maximum A Posterior...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Zill-E-Huma Kamal,Ajay Gupta,Ashfaq A. Khokhar...</td>\n",
       "      <td>IEEE Trans. Parallel Distrib. Syst.</td>\n",
       "      <td>1126381</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IT Infrastructure Emerging Markets: Arguing En...</td>\n",
       "      <td>2006</td>\n",
       "      <td>Ajay Gupta,Parthasarathy Ranganathan,Prashant ...</td>\n",
       "      <td>IEEE Pervasive Computing</td>\n",
       "      <td>1179332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Power Efficient Algorithms Computing Fast Four...</td>\n",
       "      <td>2006</td>\n",
       "      <td>Turkmen Canli,Ajay Gupta,Ashfaq Khokhar</td>\n",
       "      <td>AICCSA</td>\n",
       "      <td>1205032</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Enabling analysts managed services CRM analytics</td>\n",
       "      <td>2009</td>\n",
       "      <td>Indrajit Bhattacharya,Shantanu Godbole,Ajay Gu...</td>\n",
       "      <td>KDD</td>\n",
       "      <td>1212517</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Document Summarization Wikipedia</td>\n",
       "      <td>2009</td>\n",
       "      <td>Krishnan Ramanathan,Yogesh Sankarasubramaniam,...</td>\n",
       "      <td>Online Information Review</td>\n",
       "      <td>1265282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Performance Indicators a 802.11 WLAN Deployment.</td>\n",
       "      <td>2009</td>\n",
       "      <td>Ajay Gupta,Prabhash Dhyani</td>\n",
       "      <td>U</td>\n",
       "      <td>1316053</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Towards Automated Privacy Compliance Informati...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Rema Ananthanarayanan,Ajay Gupta,Mukesh Mohania</td>\n",
       "      <td>Advances in Web Semantics I: Ontologies, Web S...</td>\n",
       "      <td>1384744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Simulation Detection Self-Propagating Worms Vi...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>U</td>\n",
       "      <td>1393934</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A workstation's communication performance benc...</td>\n",
       "      <td>1996</td>\n",
       "      <td>Kurt Maly,Ajay Gupta,Satish Mynam</td>\n",
       "      <td>Selected proceedings of the IFIP TC6 9th inter...</td>\n",
       "      <td>1398544</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Synchronization distributed systems</td>\n",
       "      <td>1989</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>U</td>\n",
       "      <td>1490190</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Largeandmdash;scale parallel numerical integra...</td>\n",
       "      <td>1999</td>\n",
       "      <td>Elise de Doncker,Ajay Gupta,Rodger R. Zanny</td>\n",
       "      <td>Journal of Computational and Applied Mathematics</td>\n",
       "      <td>1549674</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A method efficient design Boltzmann machines c...</td>\n",
       "      <td>1990</td>\n",
       "      <td>Ajay Gupta,Wolfgang Maass</td>\n",
       "      <td>Proceedings of the 1990 conference on Advances...</td>\n",
       "      <td>1671104</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>On complexity computation learning neural netw...</td>\n",
       "      <td>1991</td>\n",
       "      <td>Ajay Gupta</td>\n",
       "      <td>U</td>\n",
       "      <td>1678096</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Hack I.T.: security through penetration testing</td>\n",
       "      <td>2002</td>\n",
       "      <td>T. J. Klevinsky,Scott Laliberte,Ajay Gupta</td>\n",
       "      <td>U</td>\n",
       "      <td>1739014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  year  \\\n",
       "5   Management Conflicting Obligations Self-Protec...  2005   \n",
       "6           Policy Framework Autonomic Data Managemen  2004   \n",
       "7   Using Lagrangean Relaxation Service Location P...  2008   \n",
       "8   Mobility-Pattern-Based Anomaly Detection Algor...  2008   \n",
       "9   Detection Masquerade Attacks Wireless Sensor N...  2007   \n",
       "10   Dynamic Access Control Framework Based On Events  2003   \n",
       "11  Towards Bringing Database Management Task Real...  2003   \n",
       "12               Enhanced Business Intelligence EROCS  2008   \n",
       "13            Hardware Diagnosis as Program Debugging  1987   \n",
       "14                Efficient Design Boltzmann Machines  1990   \n",
       "15                  Policy Driven Data Administration  2002   \n",
       "16                   Clustering short texts wikipedia  2007   \n",
       "17  LIPTUS: associating structured unstructured in...  2007   \n",
       "18        Retaining personal expression social search  2009   \n",
       "19                Some issues privacy data management  2007   \n",
       "20                       Mutual Exclusion a Hypercube  1993   \n",
       "21  Multivariate Integration Hypercubic Mesh Networks  1998   \n",
       "22  Power Consumption Analysis Maximum A Posterior...  2008   \n",
       "23  IT Infrastructure Emerging Markets: Arguing En...  2006   \n",
       "24  Power Efficient Algorithms Computing Fast Four...  2006   \n",
       "25   Enabling analysts managed services CRM analytics  2009   \n",
       "26                   Document Summarization Wikipedia  2009   \n",
       "27   Performance Indicators a 802.11 WLAN Deployment.  2009   \n",
       "28  Towards Automated Privacy Compliance Informati...  2008   \n",
       "29  Simulation Detection Self-Propagating Worms Vi...  2008   \n",
       "30  A workstation's communication performance benc...  1996   \n",
       "31                Synchronization distributed systems  1989   \n",
       "32  Largeandmdash;scale parallel numerical integra...  1999   \n",
       "33  A method efficient design Boltzmann machines c...  1990   \n",
       "34  On complexity computation learning neural netw...  1991   \n",
       "35    Hack I.T.: security through penetration testing  2002   \n",
       "\n",
       "                                              authors  \\\n",
       "5   Rema Ananthanarayanan,Mukesh K. Mohania,Ajay G...   \n",
       "6   Manish Bhide,Ajay Gupta,Mukul Joshi,Mukesh K. ...   \n",
       "7       Zill-E-Huma Kamal,Ala I. Al-Fuqaha,Ajay Gupta   \n",
       "8                               Chaoli Cai,Ajay Gupta   \n",
       "9             Vijay Bhuse,Ajay Gupta,Ala I. Al-Fuqaha   \n",
       "10  Manish Bhide,Sandeep Pandey,Ajay Gupta,Mukesh ...   \n",
       "11          Ajay Gupta,Manish Bhide,Mukesh K. Mohania   \n",
       "12  Manish Bhide,V. Chakravarthy,Ajay Gupta,Himans...   \n",
       "13                                         Ajay Gupta   \n",
       "14                          Ajay Gupta,Wolfgang Maass   \n",
       "15  Vishal S. Batra,Jaijit Bhattacharya,Harish Cha...   \n",
       "16    Somnath Banerjee,Krishnan Ramanathan,Ajay Gupta   \n",
       "17  Manish Bhide,Ajay Gupta,Rahul Gupta,Prasan Roy...   \n",
       "18                         Praphul Chandra,Ajay Gupta   \n",
       "19  Mukesh K. Mohania,Rema Ananthanarayanan,Ajay G...   \n",
       "20          Ajay Gupta,Steven C. Bruell,Sukumar Ghosh   \n",
       "21                     Elise de Doncker,Ajay K. Gupta   \n",
       "22  Zill-E-Huma Kamal,Ajay Gupta,Ashfaq A. Khokhar...   \n",
       "23  Ajay Gupta,Parthasarathy Ranganathan,Prashant ...   \n",
       "24            Turkmen Canli,Ajay Gupta,Ashfaq Khokhar   \n",
       "25  Indrajit Bhattacharya,Shantanu Godbole,Ajay Gu...   \n",
       "26  Krishnan Ramanathan,Yogesh Sankarasubramaniam,...   \n",
       "27                         Ajay Gupta,Prabhash Dhyani   \n",
       "28    Rema Ananthanarayanan,Ajay Gupta,Mukesh Mohania   \n",
       "29                                         Ajay Gupta   \n",
       "30                  Kurt Maly,Ajay Gupta,Satish Mynam   \n",
       "31                                         Ajay Gupta   \n",
       "32        Elise de Doncker,Ajay Gupta,Rodger R. Zanny   \n",
       "33                          Ajay Gupta,Wolfgang Maass   \n",
       "34                                         Ajay Gupta   \n",
       "35         T. J. Klevinsky,Scott Laliberte,Ajay Gupta   \n",
       "\n",
       "                                                jconf      pid  label  \n",
       "5                                                ICAC   264268      2  \n",
       "6                                                ICAC   264291      2  \n",
       "7                                                 ICC   275987      4  \n",
       "8                                                 ICC   276300      4  \n",
       "9                                                 ICC   277587      4  \n",
       "10                                               ICDE   299548      2  \n",
       "11                                               ICDE   300057      2  \n",
       "12                                               ICDE   302056      2  \n",
       "13                                              IJCAI   388794      0  \n",
       "14                                               NIPS   515636      7  \n",
       "15                                             POLICY   545651      2  \n",
       "16                                              SIGIR   596099      0  \n",
       "17                                  SIGMOD Conference   600181      2  \n",
       "18                                                WWW   675629      0  \n",
       "19                                   Data Knowl. Eng.   846439      2  \n",
       "20                       J. Parallel Distrib. Comput.   988870      3  \n",
       "21                                 Parallel Computing  1034401      4  \n",
       "22                IEEE Trans. Parallel Distrib. Syst.  1126381      4  \n",
       "23                           IEEE Pervasive Computing  1179332      0  \n",
       "24                                             AICCSA  1205032      4  \n",
       "25                                                KDD  1212517      2  \n",
       "26                          Online Information Review  1265282      0  \n",
       "27                                                  U  1316053      5  \n",
       "28  Advances in Web Semantics I: Ontologies, Web S...  1384744      2  \n",
       "29                                                  U  1393934      6  \n",
       "30  Selected proceedings of the IFIP TC6 9th inter...  1398544      8  \n",
       "31                                                  U  1490190      3  \n",
       "32   Journal of Computational and Applied Mathematics  1549674      4  \n",
       "33  Proceedings of the 1990 conference on Advances...  1671104      7  \n",
       "34                                                  U  1678096      7  \n",
       "35                                                  U  1739014      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.pop('author')\n",
    "dataframe = dataframe.where(dataframe.notnull(), 'U')\n",
    "dataframe.isna()\n",
    "dataframe.tail(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee8fa1b-7892-405c-a6d9-02f01bdd6b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 train examples\n",
      "6 validation examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "# test.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0afe50bd-6ab9-4566-b304-55b2c3fa3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('label')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a2048-f1e2-4aac-a060-7640c34ec624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(dataframe, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = df_to_dataset(dataframe, batch_size=batch_size)\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62bdd3d5-ecd2-4440-8ef3-5cc932baf063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = preprocessing.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "869278de-7bea-420c-96ca-c43ea39b2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a StringLookup layer which will turn strings into integer indices\n",
    "  if dtype == 'string':\n",
    "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = preprocessing.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6da3318-437e-4eb1-ace2-cd1950b5e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78b1ad0f-8d8f-4f87-ab65-7455253b2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric features.\n",
    "for header in ['pid']:\n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dc1493b-ef2f-4808-abd9-bd8c6a32f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers.\n",
    "age_col = tf.keras.Input(shape=(1,), name='year', dtype='int64')\n",
    "encoding_layer = get_category_encoding_layer('year', train_ds, dtype='int64',\n",
    "                                             max_tokens=5)\n",
    "encoded_age_col = encoding_layer(age_col)\n",
    "all_inputs.append(age_col)\n",
    "encoded_features.append(encoded_age_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "251053fc-d784-497a-aac6-7cd15f6b5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as string.\n",
    "categorical_cols = ['title', 'authors', 'jconf']\n",
    "for header in categorical_cols:\n",
    "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string',\n",
    "                                               max_tokens=5)\n",
    "  encoded_categorical_col = encoding_layer(categorical_col)\n",
    "  all_inputs.append(categorical_col)\n",
    "  encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "288b844a-b6a8-46ae-b34c-2d5cb4d4e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "\n",
    "# x = tf.keras.layers.Dense(50, activation=\"relu\")(all_features)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "# output = tf.keras.layers.Dense(1)(x)\n",
    "# model = tf.keras.Model(all_inputs, output)\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88764194-87d0-4ae1-b9bb-084447270b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc670abe-a805-4185-b617-590f7bb7e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature columns describe how to use the input.\n",
    "# my_feature_columns = []\n",
    "# for key in train.keys():\n",
    "#     my_feature_columns.append(tf.feature_column.categorical_column_with_hash_bucket('key',hash_bucket_size=1000))\n",
    "# print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53cc805a-aea3-4803-a0b5-9ba25e010982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\KHADGA~1\\AppData\\Local\\Temp\\tmpq8mtg07e\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\KHADGA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpq8mtg07e', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=all_inputs,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[50, 50],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=9\n",
    "#     ,activation_fn='relu',batch_norm=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a706ca7-7b67-4f2b-88ed-a17fc360fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received a feature column from TensorFlow v1, but this is a TensorFlow v2 Estimator. Please either use v2 feature columns (accessible via tf.feature_column.* in TF 2.x) with this Estimator, or switch to a v1 Estimator for use with v1 feature columns (accessible via tf.compat.v1.estimator.* and tf.compat.v1.feature_column.*, respectively.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KHADGA~1\\AppData\\Local\\Temp/ipykernel_13528/2372170768.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m classifier.train(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     steps=5000)\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# We include a lambda to avoid creating an inner function previously\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1201\u001b[0m           self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n\u001b[0;32m   1202\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                            self.config)\n\u001b[0;32m   1205\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m       \u001b[1;34m\"\"\"Call the defined shared dnn_model_fn_v2.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m       return dnn_model_fn_v2(\n\u001b[0m\u001b[0;32m    751\u001b[0m           \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m           \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36mdnn_model_fn_v2\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    558\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m   logits, trainable_variables, update_ops = _dnn_model_fn_builder_v2(\n\u001b[0m\u001b[0;32m    561\u001b[0m       \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits_dimension\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m       \u001b[0mhidden_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn_builder_v2\u001b[1;34m(units, hidden_units, feature_columns, activation_fn, dropout, batch_norm, features, mode)\u001b[0m\n\u001b[0;32m    494\u001b[0m     raise ValueError('units must be an int.  Given type: {}'.format(\n\u001b[0;32m    495\u001b[0m         type(units)))\n\u001b[1;32m--> 496\u001b[1;33m   dnn_model = _DNNModelV2(\n\u001b[0m\u001b[0;32m    497\u001b[0m       \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m       \u001b[0mhidden_units\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, hidden_units, feature_columns, activation_fn, dropout, batch_norm, name, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m             feature_columns=feature_columns, name=layer_name)\n\u001b[0;32m    295\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;34m'Received a feature column from TensorFlow v1, but this is a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;34m'TensorFlow v2 Estimator. Please either use v2 feature columns '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Received a feature column from TensorFlow v1, but this is a TensorFlow v2 Estimator. Please either use v2 feature columns (accessible via tf.feature_column.* in TF 2.x) with this Estimator, or switch to a v1 Estimator for use with v1 feature columns (accessible via tf.compat.v1.estimator.* and tf.compat.v1.feature_column.*, respectively."
     ]
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, training=True),\n",
    "    steps=5000)\n",
    "# We include a lambda to avoid creating an inner function previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267f8fb-f3f8-47eb-9705-31a77f7f18a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
