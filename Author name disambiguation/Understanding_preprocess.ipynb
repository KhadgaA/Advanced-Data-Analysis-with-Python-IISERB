{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e11d87d-a63a-4009-a0d3-4479f4fcf40e",
   "metadata": {},
   "source": [
    "## This is for understanding preprocessing of data\n",
    ">https://github.com/joe817/name-disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc72ae71-819e-4b97-a66e-4b4b34972b97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KHADGA~1\\AppData\\Local\\Temp/ipykernel_10416/1395176682.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAgglomerativeClustering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "#data processing\n",
    "\n",
    "import pickle\n",
    "from gensim.models import word2vec\n",
    "import networkx as nx \n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import  xml.dom.minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import os\n",
    "import numpy as np \n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88420446-4645-4427-b24a-1f6a56116f25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KHADGA~1\\AppData\\Local\\Temp/ipykernel_10416/3761421683.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'author-disambiguation-data/data/raw-data/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfile_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[!“”\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~—～]+'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstopword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'at'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'based'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'in'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'of'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'for'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'on'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'and'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'to'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'an'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'using'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'with'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'the'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "path = 'author-disambiguation-data/data/raw-data/'\n",
    "file_names = os.listdir(path)\n",
    "\n",
    "r = '[!“”\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~—～]+'\n",
    "stopword = ['at','based','in','of','for','on','and','to','an','using','with','the']\n",
    "\n",
    "keyid=0\n",
    "papers = {}\n",
    "authors = {}\n",
    "jconfs = {}\n",
    "word={}\n",
    "\n",
    "for fname in file_names:\n",
    "    f = open(path + fname,'r',encoding = 'utf-8').read()\n",
    "    text=re.sub(u\"&\",u\" \",f)\n",
    "    root = ET.fromstring(text)\n",
    "\n",
    "    for i in root.findall('publication'):\n",
    "        paper = i.find('title').text\n",
    "        pid = i.find('id').text\n",
    "        papers[pid] = paper\n",
    "        \n",
    "    \n",
    "for fname in file_names:\n",
    "    f = open(path + fname,'r',encoding = 'utf-8').read()\n",
    "    text=re.sub(u\"&\",u\" \",f)\n",
    "    root = ET.fromstring(text)\n",
    "\n",
    "    for i in root.findall('publication'):\n",
    "        jconf = i.find('jconf').text.strip().replace(\" \", \"\")\n",
    "        if jconf not in jconfs:\n",
    "            jconfs[jconf] = keyid\n",
    "            keyid = keyid + 1\n",
    "\n",
    "authorid=0\n",
    "author1={}            \n",
    "for fname in file_names:\n",
    "    f = open(path + fname,'r',encoding = 'utf-8').read()\n",
    "    text=re.sub(u\"&\",u\" \",f)\n",
    "    root = ET.fromstring(text)\n",
    "\n",
    "    for i in root.findall('publication'):\n",
    "        authorlist = i.find('authors').text.strip().split(\",\")\n",
    "        for author in authorlist:\n",
    "            author = author.replace(\" \", \"\")\n",
    "            if author not in authors:\n",
    "                authors[author] = keyid\n",
    "                keyid = keyid + 1 \n",
    "    if fname not in author1:\n",
    "        author1[fname] = authorid\n",
    "        authorid = authorid + 1\n",
    "\n",
    "        \n",
    "for fname in file_names:\n",
    "    f = open(path + fname,'r',encoding = 'utf-8').read()\n",
    "    text=re.sub(u\"&\",u\" \",f)\n",
    "    root = ET.fromstring(text)\n",
    "    \n",
    "    for i in root.findall('publication'):\n",
    "        pid = i.find('id').text\n",
    "        line = i.find('title').text\n",
    "        line = re.sub(r, ' ', line)\n",
    "        line = line.replace('\\t',' ')\n",
    "        line = line.lower()\n",
    "            #f1.write(line+'\\n')\n",
    "\n",
    "        split_cut = line.split(' ')\n",
    "        for j in split_cut:\n",
    "            if len(j)>1 and (j not in stopword):\n",
    "                if j not in word:\n",
    "                    word[j] = 1\n",
    "                else:\n",
    "                    word[j] = word[j] +1\n",
    "\n",
    "                    \n",
    "                    \n",
    "f1 = open ('gene/paper_author.txt','w',encoding = 'utf-8')\n",
    "f2 = open ('gene/paper_conf.txt','w',encoding = 'utf-8')\n",
    "f3 = open ('gene/paper_word.txt','w',encoding = 'utf-8')\n",
    "\n",
    "f4 = open ('gene/paper_author1.txt','w',encoding = 'utf-8')\n",
    "f5 = open ('gene/paper_title.txt','w',encoding = 'utf-8')\n",
    "\n",
    "\n",
    "for fname in file_names:\n",
    "    f = open(path + fname,'r',encoding = 'utf-8').read()\n",
    "    text=re.sub(u\"&\",u\" \",f)\n",
    "    root = ET.fromstring(text)\n",
    "\n",
    "    for i in root.findall('publication'):\n",
    "        pid = i.find('id').text\n",
    "        authorlist = i.find('authors').text.strip().split(\",\")\n",
    "        jconf = i.find('jconf').text.strip().replace(\" \", \"\")\n",
    "        f4.write('i'+pid + '\\t' + str(author1[fname]) + '\\n')\n",
    "        for author in authorlist:\n",
    "            if author!=fname[:-4]:\n",
    "                if (author+'.xml') in author1:\n",
    "                    f4.write('i'+pid + '\\t' + str(author1[author+'.xml']) + '\\n')\n",
    "                author = author.replace(\" \", \"\")\n",
    "                f1.write('i'+pid + '\\t' + str(authors[author]) + '\\n')\n",
    "\n",
    "        f2.write('i'+pid + '\\t' + str(jconfs[jconf]) + '\\n')\n",
    "        \n",
    "        line = i.find('title').text\n",
    "        line = re.sub(r, ' ', line)\n",
    "        line = line.replace('\\t',' ')\n",
    "        line = line.lower()\n",
    "        f5.write('i' + pid +'\\t' + line + '\\n')\n",
    "            \n",
    "        split_cut = line.split(' ')\n",
    "        for j in split_cut:\n",
    "            if (j in word)and (word[j]>=2):\n",
    "                f3.write('i' + pid +'\\t' + j + '\\n')\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "f1.close()\n",
    "f2.close()\n",
    "f3.close()\n",
    "f4.close()\n",
    "f5.close()\n",
    "\n",
    "print(len(author1),\"ambiguous names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a5cad-f354-47db-86b3-cc8a8df6bc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
